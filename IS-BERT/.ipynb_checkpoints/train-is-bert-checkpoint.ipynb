{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-01T14:01:43.086658Z",
     "iopub.status.busy": "2021-07-01T14:01:43.086325Z",
     "iopub.status.idle": "2021-07-01T14:01:43.096208Z",
     "shell.execute_reply": "2021-07-01T14:01:43.09536Z",
     "shell.execute_reply.started": "2021-07-01T14:01:43.086626Z"
    },
    "id": "Gs6D2DmpxhVG",
    "outputId": "4af14907-eb13-413f-d467-a573692cb0f1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../input/one-file/IS-BERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-01T14:01:44.728362Z",
     "iopub.status.busy": "2021-07-01T14:01:44.727934Z",
     "iopub.status.idle": "2021-07-01T14:01:50.607964Z",
     "shell.execute_reply": "2021-07-01T14:01:50.607023Z",
     "shell.execute_reply.started": "2021-07-01T14:01:44.728322Z"
    },
    "id": "wA2CJKUwxwP1",
    "outputId": "0c7c7faa-126a-4c8f-97f4-01933c34b2c2"
   },
   "outputs": [],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-01T14:01:50.610676Z",
     "iopub.status.busy": "2021-07-01T14:01:50.610403Z",
     "iopub.status.idle": "2021-07-01T14:01:57.383127Z",
     "shell.execute_reply": "2021-07-01T14:01:57.382269Z",
     "shell.execute_reply.started": "2021-07-01T14:01:50.610648Z"
    },
    "id": "ONo0UqO6wI2o"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "from sentence_transformers import models, losses\n",
    "from sentence_transformers import SentencesDataset, LoggingHandler, SentenceTransformer, util, InputExample\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import gzip\n",
    "import csv\n",
    "from importlib import reload\n",
    "import pickle\n",
    "import codecs\n",
    "import torch\n",
    "from transformers import AdamW\n",
    "from tqdm.autonotebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-01T14:01:57.385228Z",
     "iopub.status.busy": "2021-07-01T14:01:57.384885Z",
     "iopub.status.idle": "2021-07-01T14:01:57.390273Z",
     "shell.execute_reply": "2021-07-01T14:01:57.388973Z",
     "shell.execute_reply.started": "2021-07-01T14:01:57.385193Z"
    },
    "id": "8dNSU5TJ6sBm"
   },
   "outputs": [],
   "source": [
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(format='%(asctime)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                    level=logging.INFO,\n",
    "                    handlers=[LoggingHandler()])\n",
    "#### /print debug information to stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-01T14:02:29.141991Z",
     "iopub.status.busy": "2021-07-01T14:02:29.141644Z",
     "iopub.status.idle": "2021-07-01T14:02:36.518252Z",
     "shell.execute_reply": "2021-07-01T14:02:36.51718Z",
     "shell.execute_reply.started": "2021-07-01T14:02:29.141954Z"
    },
    "id": "Of3ceT-F62wh",
    "outputId": "684160e1-1980-4e30-ab5b-9efdfd8c9790"
   },
   "outputs": [],
   "source": [
    "# Read the dataset.\n",
    "train_batch_size = 32\n",
    "\n",
    "# os.chdir(\"input\")\n",
    "# !ls\n",
    "os.chdir('..')\n",
    "!ls\n",
    "\n",
    "word_embedding_model = models.Transformer('kaggle/input/distilBERTQuine_lr_4e-5_epochs_20')\n",
    "cnn = models.CNN(in_word_embedding_dimension=word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "# Apply mean pooling to get one fixed sized sentence vector.\n",
    "pooling_model = models.Pooling(cnn.get_word_embedding_dimension(),\n",
    "                               pooling_mode_mean_tokens=True,\n",
    "                               pooling_mode_cls_token=False,\n",
    "                               pooling_mode_max_tokens=False)\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, cnn, pooling_model])\n",
    "\n",
    "\n",
    "#model.encode(\"telepathy is nice\", convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-01T14:53:02.19703Z",
     "iopub.status.busy": "2021-07-01T14:53:02.196694Z",
     "iopub.status.idle": "2021-07-01T14:53:14.906417Z",
     "shell.execute_reply": "2021-07-01T14:53:14.905533Z",
     "shell.execute_reply.started": "2021-07-01T14:53:02.197Z"
    },
    "id": "-NWqPRnEIMqQ",
    "outputId": "25deae24-7d55-4a54-ff4f-87952c728452"
   },
   "outputs": [],
   "source": [
    "train_samples = []\n",
    "os.chdir('..')\n",
    "!ls\n",
    "sentences = open('kaggle/input/one-file/IS-BERT/quinev05_input_word.txt', 'r').readlines()\n",
    "for s in sentences:\n",
    "    sentence = s.strip().split('\\n')[0]\n",
    "    train_samples.append(InputExample(texts=[sentence], label=4))\n",
    "\n",
    "# Configure the training.\n",
    "train_dataset= SentencesDataset(train_samples, model=model)\n",
    "for elem in train_dataset:\n",
    "  ids = elem[0][0]\n",
    "  if len(ids) > 512:\n",
    "    del ids[512:]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.MutualInformationLoss(model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension())\n",
    "\n",
    "# Configure the training.\n",
    "num_epochs = 13\n",
    "warmup_steps = math.ceil(len(train_dataset) * num_epochs / train_batch_size * 0.1)\n",
    "\n",
    "for elem in train_dataset:\n",
    "  if len(elem[0][0])> 512:\n",
    "    print(\"Indexing error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-01T14:53:14.912124Z",
     "iopub.status.busy": "2021-07-01T14:53:14.911846Z",
     "iopub.status.idle": "2021-07-01T15:19:00.894879Z",
     "shell.execute_reply": "2021-07-01T15:19:00.893891Z",
     "shell.execute_reply.started": "2021-07-01T14:53:14.912096Z"
    },
    "id": "YN85HG4-EgJS",
    "outputId": "716a07bf-91f0-4d06-b0a1-25c116edb242"
   },
   "outputs": [],
   "source": [
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          weight_decay= 0.00,\n",
    "          optimizer_params = {'lr': 2e-8, 'eps': 2e-9, 'correct_bias': False},\n",
    "          scheduler= 'warmuplinear'\n",
    "          ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6chFvYTEO1_8"
   },
   "outputs": [],
   "source": [
    "#fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-01T13:19:03.566287Z",
     "iopub.status.busy": "2021-07-01T13:19:03.565926Z",
     "iopub.status.idle": "2021-07-01T13:19:03.571877Z",
     "shell.execute_reply": "2021-07-01T13:19:03.571031Z",
     "shell.execute_reply.started": "2021-07-01T13:19:03.566248Z"
    },
    "id": "KX1SOAXVB3_U",
    "outputId": "18c8019d-c5df-4530-b2b1-0ae70e32c5ac"
   },
   "outputs": [],
   "source": [
    "#model.encode('telepathy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-01T15:35:53.033165Z",
     "iopub.status.busy": "2021-07-01T15:35:53.032823Z",
     "iopub.status.idle": "2021-07-01T15:37:03.690026Z",
     "shell.execute_reply": "2021-07-01T15:37:03.689109Z",
     "shell.execute_reply.started": "2021-07-01T15:35:53.033136Z"
    },
    "id": "RZ3Vbs6lqsLS"
   },
   "outputs": [],
   "source": [
    "stripped = []\n",
    "for sentence in sentences:\n",
    "    sentence = sentence.strip('\\n')\n",
    "    stripped.append(sentence)\n",
    "print(len(stripped))\n",
    "embeddings = model.encode(stripped, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-01T15:37:03.693146Z",
     "iopub.status.busy": "2021-07-01T15:37:03.692657Z",
     "iopub.status.idle": "2021-07-01T15:37:03.703053Z",
     "shell.execute_reply": "2021-07-01T15:37:03.702264Z",
     "shell.execute_reply.started": "2021-07-01T15:37:03.693105Z"
    },
    "id": "xuXvKjKyKmLb"
   },
   "outputs": [],
   "source": [
    "def testISqueryrun(test_annot, query, n, docid, embeddings):\n",
    "\n",
    "    model.max_seq_length = 512\n",
    "\n",
    "\n",
    "    a = codecs.open(test_annot, encoding=\"utf-8\")\n",
    "    annot_corpus = a.readlines()\n",
    "    annot_corpus = [i.split() for i in annot_corpus]\n",
    "\n",
    "    apscore10_eval = []\n",
    "    apscore100_eval = []\n",
    "    apscore500_eval = []\n",
    "    f10_eval = []\n",
    "    f100_eval = []\n",
    "    f500_eval = []\n",
    "    pc10_eval = []\n",
    "    pc100_eval = []\n",
    "    pc500_eval = []\n",
    "    pcr_eval = []\n",
    "    pcr_r_eval = []\n",
    "    pcr_m_eval = []\n",
    "    pcr_i_eval = []\n",
    "    avgrank_all_eval = []\n",
    "    avgrank_500_eval = []\n",
    "    avgdist_all_eval = []\n",
    "    avgdist_500_eval = []\n",
    "\n",
    "    for i in range(n):\n",
    "        apscore10, apscore100, apscore500, pc10, pc100, pc500, f10, f100, f500, pcr, pcr_r, pcr_m, pcr_i, avgrank_all, avgrank_500, avgdist_all, avgdist_500 = testISquery(annot_corpus, model, embeddings, query, docid)\n",
    "        #print(apscore10, apscore100, apscore500, pc10, pc100, pc500, f10, f100, f500, pcr, pcr_r, pcr_m, pcr_i, avgrank_all, avgrank_500, avgdist_all, avgdist_500)\n",
    "        apscore10_eval.append(apscore10)\n",
    "        apscore100_eval.append(apscore100)\n",
    "        apscore500_eval.append(apscore500)\n",
    "        f10_eval.append(f10)\n",
    "        f100_eval.append(f100)\n",
    "        f500_eval.append(f500)\n",
    "        pc10_eval.append(pc10)\n",
    "        pc100_eval.append(pc100)\n",
    "        pc500_eval.append(pc500)\n",
    "        pcr_eval.append(pcr)\n",
    "        pcr_r_eval.append(pcr_r)\n",
    "        pcr_m_eval.append(pcr_m)\n",
    "        pcr_i_eval.append(pcr_i)\n",
    "        avgrank_all_eval.append(avgrank_all)\n",
    "        avgrank_500_eval.append(avgrank_500)\n",
    "        avgdist_all_eval.append(avgdist_all)\n",
    "        avgdist_500_eval.append(avgdist_500)\n",
    "\n",
    "    print(pcr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-01T15:37:03.705219Z",
     "iopub.status.busy": "2021-07-01T15:37:03.704739Z",
     "iopub.status.idle": "2021-07-01T15:37:03.750475Z",
     "shell.execute_reply": "2021-07-01T15:37:03.749636Z",
     "shell.execute_reply.started": "2021-07-01T15:37:03.705181Z"
    },
    "id": "PfnbOXswKrGW"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "def most_similar(emb_matrix, qvector, n):\n",
    "    sims = []\n",
    "    top_k = n\n",
    "    cos_scores = util.pytorch_cos_sim(qvector, emb_matrix)[0]\n",
    "    cos_scores = cos_scores.cpu()\n",
    "\n",
    "    top_results = torch.topk(cos_scores, k=top_k)\n",
    "    for score, idx in zip(top_results[0], top_results[1]):\n",
    "        sims.append((idx, score))\n",
    "    return sims\n",
    "\n",
    "def testISquery(annot_corpus, model, embeddings, query, docid):\n",
    "    #Performs a single query and computes evaluation metrics over it. Supports summed query vectors (add), inferred query vectors (inf) and taking a trained document vector as a query vector (trn).\n",
    "    #If a docID is provided, it will use that as a query, otherwise it will use 'query'.\n",
    "\n",
    "    annot_hits = []\n",
    "    annot_hits_m = []\n",
    "    annot_hits_r = []\n",
    "    annot_hits_i = []\n",
    "    for i, line in enumerate(annot_corpus):\n",
    "        if line:\n",
    "            if '@' in line[0]:\n",
    "                if '@1' in line[0]:\n",
    "                    annot_hits.append(i)\n",
    "                    annot_hits_r.append(i)\n",
    "                if '@0' in line[0]:\n",
    "                    annot_hits.append(i)\n",
    "                    annot_hits_m.append(i)\n",
    "                if '@-1' in line[0]:\n",
    "                    annot_hits_i.append(i)\n",
    "    #print('annot_hits', annot_hits)\n",
    "    if docid:\n",
    "        qvector = embeddings[docid]\n",
    "\n",
    "    else:\n",
    "        \n",
    "        qvector = model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "    #logger.info('10 most similar words to query vector = {}'.format(model.similar_by_vector(qvector, topn=10)))\n",
    "\n",
    "    sims = most_similar(embeddings, qvector, len(stripped))\n",
    "    sims10 = sims[:10]\n",
    "    sims100 = sims[:100]\n",
    "    \n",
    "    matches = {}\n",
    "    matches_r = {}\n",
    "    matches_m = {}\n",
    "    matches_i = {}\n",
    "    total = 0\n",
    "    top10 = 0\n",
    "    top1 = 0\n",
    "    top100 = 0\n",
    "    top500 = 0\n",
    "    top_r = 0 #For computing precision @ R (recall, the number of target documents)\n",
    "    eval_avgrank = []\n",
    "    eval_avg_distance_between = []\n",
    "    eval_avgrank_all = []\n",
    "    eval_avg_distance_between_all = []\n",
    "\n",
    "    total_r = 0\n",
    "    top10_r = 0\n",
    "    top1_r = 0\n",
    "    top100_r = 0\n",
    "    top500_r = 0\n",
    "    top_r_r = 0\n",
    "    eval_avgrank_r = []\n",
    "    eval_avg_distance_between_r = []\n",
    "    eval_avgrank_all_r = []\n",
    "    eval_avg_distance_between_all_r = []\n",
    "\n",
    "    total_m = 0\n",
    "    top10_m = 0\n",
    "    top1_m = 0\n",
    "    top100_m = 0\n",
    "    top500_m = 0\n",
    "    top_r_m = 0\n",
    "    eval_avgrank_m = []\n",
    "    eval_avg_distance_between_m = []\n",
    "    eval_avgrank_all_m = []\n",
    "    eval_avg_distance_between_all_m = []\n",
    "\n",
    "    total_i = 0\n",
    "    top10_i = 0\n",
    "    top1_i = 0\n",
    "    top100_i = 0\n",
    "    top500_i = 0\n",
    "    top_r_i = 0\n",
    "    eval_avgrank_i = []\n",
    "    eval_avg_distance_between_i = []\n",
    "    eval_avgrank_all_i = []\n",
    "    eval_avg_distance_between_all_i = []\n",
    "\n",
    "    total_match = len(annot_hits)\n",
    "    total_match_r = len(annot_hits_r)\n",
    "    total_match_m = len(annot_hits_m)\n",
    "    total_match_i = len(annot_hits_i)\n",
    "    total = len(annot_corpus)\n",
    "\n",
    "    #for line in annot_hits:\n",
    "    #    annotation = line.split(',')\n",
    "    rank = 1\n",
    "    for match in sims:\n",
    "        if match[0] in annot_hits:\n",
    "            #Count total hits of relevant passages\n",
    "            matches[match[0]] = (rank,match[1])\n",
    "            eval_avgrank_all.append(rank)\n",
    "            eval_avg_distance_between_all.append(match[1])\n",
    "            if rank < 501:\n",
    "                eval_avgrank.append(rank)\n",
    "                eval_avg_distance_between.append(match[1])\n",
    "                top500 = top500 + 1\n",
    "                if rank < 101:\n",
    "                    top100 = top100 + 1\n",
    "                    if rank < 11:\n",
    "                        top10 = top10 + 1\n",
    "                        if rank == 1:\n",
    "                            top1 = top1 + 1\n",
    "            if rank < total_match:\n",
    "                top_r = top_r + 1\n",
    "\n",
    "        if match[0] in annot_hits_r:\n",
    "            matches_r[match[0]] = (rank,match[1])\n",
    "            eval_avgrank_all_r.append(rank)\n",
    "            eval_avg_distance_between_all_r.append(match[1])\n",
    "            if rank < 501:\n",
    "                eval_avgrank_r.append(rank)\n",
    "                eval_avg_distance_between_r.append(match[1])\n",
    "                top500_r = top500_r + 1\n",
    "                if rank < 101:\n",
    "                    top100_r = top100_r + 1\n",
    "                    if rank < 11:\n",
    "                        top10_r = top10_r + 1\n",
    "                        if rank == 1:\n",
    "                            top1_r = top1_r + 1\n",
    "            if rank < total_match_r:\n",
    "                top_r_r = top_r_r + 1\n",
    "\n",
    "        if match[0] in annot_hits_m:\n",
    "            matches_m[match[0]] = (rank,match[1])\n",
    "            eval_avgrank_all_m.append(rank)\n",
    "            eval_avg_distance_between_all_m.append(match[1])\n",
    "            if rank < 501:\n",
    "                eval_avgrank_m.append(rank)\n",
    "                eval_avg_distance_between_m.append(match[1])\n",
    "                top500_m = top500_m + 1\n",
    "                if rank < 101:\n",
    "                    top100_m = top100_m + 1\n",
    "                    if rank < 11:\n",
    "                        top10_m = top10_m + 1\n",
    "                        if rank == 1:\n",
    "                            top1_m = top1_m + 1\n",
    "            if rank < total_match_m:\n",
    "                top_r_m = top_r_m + 1\n",
    "        #rank = rank + 1\n",
    "\n",
    "        if match[0] in annot_hits_i:\n",
    "            matches_i[match[0]] = (rank,match[1])\n",
    "            eval_avgrank_all_i.append(rank)\n",
    "            eval_avg_distance_between_all_i.append(match[1])\n",
    "            if rank < 501:\n",
    "                eval_avgrank_i.append(rank)\n",
    "                eval_avg_distance_between_i.append(match[1])\n",
    "                top500_i = top500_i + 1\n",
    "                if rank < 101:\n",
    "                    top100_i = top100_i + 1\n",
    "                    if rank < 11:\n",
    "                        top10_i = top10_i + 1\n",
    "                        if rank == 1:\n",
    "                            top1_i = top1_i + 1\n",
    "            if rank < total_match_i:\n",
    "                top_r_i = top_r_i + 1\n",
    "        rank = rank + 1\n",
    "        \n",
    "    i = 0\n",
    "  \n",
    "    #top_r = top_r_r + top_r_m\n",
    "    print(top_r,top_r_r , top_r_m, top_r_i)\n",
    "    #Compute Average Precision metric for the total, scientistic and modest hits\n",
    "    ap = []\n",
    "    ap_r = []\n",
    "    ap_m = []\n",
    "    ap_i = []\n",
    "    for rank in sorted(eval_avgrank):\n",
    "        i=i+1\n",
    "        ap.append(i/rank)\n",
    "        if rank in eval_avgrank_r:\n",
    "            ap_r.append(i/rank)\n",
    "        if rank in eval_avgrank_m:\n",
    "            ap_m.append(i/rank)\n",
    "        if rank in eval_avgrank_i:\n",
    "            ap_i.append(i/rank)\n",
    "\n",
    "    if ap:\n",
    "        apscore = sum(ap)/float(len(ap))\n",
    "    else:\n",
    "        apscore = 0\n",
    "    if ap_r:\n",
    "        apscore_r = sum(ap_r)/float(len(ap_r))\n",
    "    else:\n",
    "        apscore_r = 0\n",
    "    if ap_m:\n",
    "        apscore_m = sum(ap_m)/float(len(ap_m))\n",
    "    else:\n",
    "        apscore_m = 0\n",
    "    if ap_i:\n",
    "        apscore_i = sum(ap_i)/float(len(ap_i))\n",
    "    else:\n",
    "        apscore_i = 0\n",
    "\n",
    "    i = 0\n",
    "    ap100 = []\n",
    "    ap100_r = []\n",
    "    ap100_m = []\n",
    "    ap100_i = []\n",
    "    for rank in sorted(eval_avgrank):\n",
    "        if rank < 101:\n",
    "            i=i+1\n",
    "            ap100.append(i/rank)\n",
    "            if rank in eval_avgrank_r:\n",
    "                ap100_r.append(i/rank)\n",
    "            if rank in eval_avgrank_m:\n",
    "                ap100_m.append(i/rank)\n",
    "            if rank in eval_avgrank_i:\n",
    "                ap100_i.append(i/rank)\n",
    "    if ap100:\n",
    "        apscore100 = sum(ap100)/float(len(ap100))\n",
    "    else:\n",
    "        apscore100 = 0\n",
    "    if ap100_r:\n",
    "        apscore100_r = sum(ap100_r)/float(len(ap100_r))\n",
    "    else:\n",
    "        apscore100_r = 0\n",
    "    if ap100_m:\n",
    "        apscore100_m = sum(ap100_m)/float(len(ap100_m))\n",
    "    else:\n",
    "        apscore100_m = 0\n",
    "    if ap100_i:\n",
    "        apscore100_i = sum(ap100_i)/float(len(ap100_i))\n",
    "    else:\n",
    "        apscore100_i = 0\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    ap10 = []\n",
    "    ap10_r = []\n",
    "    ap10_m = []\n",
    "    ap10_i = []\n",
    "    for rank in sorted(eval_avgrank):\n",
    "        if rank < 11:\n",
    "            i=i+1\n",
    "            ap10.append(i/rank)\n",
    "            if rank in eval_avgrank_r:\n",
    "                ap10_r.append(i/rank)\n",
    "            if rank in eval_avgrank_m:\n",
    "                ap10_m.append(i/rank)\n",
    "            if rank in eval_avgrank_i:\n",
    "                ap10_i.append(i/rank)\n",
    "    if ap10:\n",
    "        apscore10 = sum(ap10)/float(len(ap10))\n",
    "    else:\n",
    "        apscore10 = 0\n",
    "    if ap10_r:\n",
    "        apscore10_r = sum(ap10_r)/float(len(ap10_r))\n",
    "    else:\n",
    "        apscore10_r = 0\n",
    "    if ap10_m:\n",
    "        apscore10_m = sum(ap10_m)/float(len(ap10_m))\n",
    "    else:\n",
    "        apscore10_m = 0\n",
    "    if ap10_i:\n",
    "        apscore10_i = sum(ap10_i)/float(len(ap10_i))\n",
    "    else:\n",
    "        apscore10_i = 0\n",
    "\n",
    "    #Compute overall precision\n",
    "    pc10 = top10/float(10)\n",
    "    pc100 = top100/float(100)\n",
    "    pc500 = top500/float(500)\n",
    "    pcr = top_r/float(total_match) # R-Precision\n",
    "\n",
    "    #Compute overall recall\n",
    "    rc10 = top10/float(total_match)\n",
    "    rc100 = top100/float(total_match)\n",
    "    rc500 = top500/float(total_match)\n",
    "\n",
    "    #Compute specific precision\n",
    "    pcr_r = top_r_r/float(total_match_r)\n",
    "    pcr_m = top_r_m/float(total_match_m)\n",
    "    pcr_i = top_r_i/float(total_match_i)\n",
    "\n",
    "    #Compute F-scores\n",
    "    if pc10+rc10:\n",
    "        f10 = 2*(pc10*rc10)/(pc10+rc10)\n",
    "    else:\n",
    "        f10 = 0\n",
    "    if pc100+rc100:\n",
    "        f100 = 2*(pc100*rc100)/(pc100+rc100)\n",
    "    else:\n",
    "        f100 = 0\n",
    "    if pc500+rc500:\n",
    "        f500 = 2*(pc500*rc500)/(pc500+rc500)\n",
    "    else:\n",
    "        f500 = 0\n",
    "\n",
    "\n",
    "\n",
    "    if eval_avgrank:\n",
    "        #print(eval_avgrank)\n",
    "        return apscore10, apscore100, apscore, pc10, pc100, pc500, f10, f100, f500, pcr, pcr_r, pcr_m, pcr_i, sum(eval_avgrank_all)/float(len(eval_avgrank_all)), sum(eval_avgrank)/float(len(eval_avgrank)), sum(eval_avg_distance_between_all)/float(len(eval_avg_distance_between_all)), sum(eval_avg_distance_between)/float(len(eval_avg_distance_between))\n",
    "    else:\n",
    "        return apscore10, apscore100, apscore, pc10, pc100, pc500, f10, f100, f500, pcr, pcr_r, pcr_m, pcr_i, sum(eval_avgrank_all)/float(len(eval_avgrank_all)), 0, sum(eval_avg_distance_between_all)/float(len(eval_avg_distance_between_all)), 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-01T15:39:01.930347Z",
     "iopub.status.busy": "2021-07-01T15:39:01.92999Z",
     "iopub.status.idle": "2021-07-01T15:40:13.225866Z",
     "shell.execute_reply": "2021-07-01T15:40:13.225039Z",
     "shell.execute_reply.started": "2021-07-01T15:39:01.930317Z"
    },
    "id": "KMPY7nIpK6Z5",
    "outputId": "e761eaf9-5570-4429-fbd4-325bfd588708"
   },
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "testISqueryrun('kaggle/input/one-file/IS-BERT/quinev05_annotU_input_word.txt', 'telepathy', 1, None, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-01T14:51:59.513377Z",
     "iopub.status.busy": "2021-07-01T14:51:59.513002Z",
     "iopub.status.idle": "2021-07-01T14:52:00.285419Z",
     "shell.execute_reply": "2021-07-01T14:52:00.284549Z",
     "shell.execute_reply.started": "2021-07-01T14:51:59.513326Z"
    },
    "id": "B4ykQbs3jh6s"
   },
   "outputs": [],
   "source": [
    "model.save('./')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
